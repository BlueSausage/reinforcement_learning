{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "import gymnasium as gym\n",
    "import itertools\n",
    "from agent import DQNAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.0005\n",
    "\n",
    "gamma = 0.999\n",
    "max_num_episodes = 1000\n",
    "hidden_size = [128, 64]\n",
    "min_epsilon = 0.01\n",
    "max_eps_episode = 150\n",
    "\n",
    "print_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_agent(config):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    env = gym.make('LunarLander-v3', continuous=False, enable_wind=False)\n",
    "    \n",
    "    agent = DQNAgent(\n",
    "        env, \n",
    "        hidden_size=config['hidden_size'], \n",
    "        batch_size=BATCH_SIZE,\n",
    "        replay_buffer_size=10000,\n",
    "        learning_rate=config['learning_rate'],\n",
    "        gamma=config['gamma'],\n",
    "        min_epsilon=min_epsilon, \n",
    "        max_eps_episode=max_eps_episode, \n",
    "        num_episodes=config.get('num_episodes', 1000),\n",
    "        print_every=500\n",
    "    )\n",
    "    \n",
    "    scores, avg_scores = agent.learn(epsilon_decay_fn=agent.exponential_epsilon_decay)\n",
    "    \n",
    "    final_avg_score = avg_scores[-1]\n",
    "    tune.report({\"final_avg_score\":final_avg_score})\n",
    "    \n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.init(ignore_reinit_error=True) # Ignore error if already initialized\n",
    "\n",
    "hidden_layer = [list(x) for x in itertools.permutations([32, 64, 128], 2)]\n",
    "\n",
    "analysis = tune.run(\n",
    "    train_agent,\n",
    "    config={\n",
    "        'learning_rate': 0.0005,\n",
    "        'hidden_size': tune.grid_search(hidden_layer),\n",
    "        'gamma': 0.999,\n",
    "        'num_episodes': 1000\n",
    "    },\n",
    "    metric='final_avg_score',\n",
    "    mode='max',\n",
    "    num_samples=1,\n",
    "    verbose=1\n",
    ")\n",
    "print('Best hyperparameters found were: ', analysis.get_best_config(metric='final_avg_score', mode='max'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DQN\n",
    "\n",
    "Current best trial: 56185_00005 with final_avg_score=198.6452985509797 and params={'learning_rate': 0.0005, 'hidden_size': [128, 64], 'gamma': 0.999, 'num_episodes': 1000}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
